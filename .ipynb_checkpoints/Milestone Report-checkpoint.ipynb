{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "blogs <- readLines(\"en_US.blogs.txt\", encoding = \"UTF-8\", skipNul = TRUE)\n",
    "news <- readLines(\"en_US.news.txt\", encoding = \"UTF-8\", skipNul = TRUE)\n",
    "twitter <- readLines(\"en_US.twitter.txt\", encoding = \"UTF-8\", skipNul = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Getting data and exploratory analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>source</th><th scope=col>file.size.MB</th><th scope=col>num.lines</th><th scope=col>num.words</th><th scope=col>mean.num.words</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>blogs   </td><td>200.4242</td><td> 899288 </td><td>37546246</td><td>41.75108</td></tr>\n",
       "\t<tr><td>news    </td><td>196.2775</td><td>1010242 </td><td>34762395</td><td>34.40997</td></tr>\n",
       "\t<tr><td>twitter </td><td>159.3641</td><td>2360148 </td><td>30093410</td><td>12.75065</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       " source & file.size.MB & num.lines & num.words & mean.num.words\\\\\n",
       "\\hline\n",
       "\t blogs    & 200.4242 &  899288  & 37546246 & 41.75108\\\\\n",
       "\t news     & 196.2775 & 1010242  & 34762395 & 34.40997\\\\\n",
       "\t twitter  & 159.3641 & 2360148  & 30093410 & 12.75065\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "source | file.size.MB | num.lines | num.words | mean.num.words | \n",
       "|---|---|---|\n",
       "| blogs    | 200.4242 |  899288  | 37546246 | 41.75108 | \n",
       "| news     | 196.2775 | 1010242  | 34762395 | 34.40997 | \n",
       "| twitter  | 159.3641 | 2360148  | 30093410 | 12.75065 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  source  file.size.MB num.lines num.words mean.num.words\n",
       "1 blogs   200.4242      899288   37546246  41.75108      \n",
       "2 news    196.2775     1010242   34762395  34.40997      \n",
       "3 twitter 159.3641     2360148   30093410  12.75065      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(stringi)\n",
    "\n",
    "## File sizes in MB\n",
    "blogs.size <- file.info(\"en_US.blogs.txt\")$size / 1024 ^ 2\n",
    "news.size <- file.info(\"en_US.news.txt\")$size / 1024 ^ 2\n",
    "twitter.size <- file.info(\"en_US.twitter.txt\")$size / 1024 ^ 2\n",
    "\n",
    "# Number words in files\n",
    "blogs.words <- stri_count_words(blogs)\n",
    "news.words <- stri_count_words(news)\n",
    "twitter.words <- stri_count_words(twitter)\n",
    "\n",
    "# Summary data frame\n",
    "data.frame(source = c(\"blogs\", \"news\", \"twitter\"),\n",
    "           file.size.MB = c(blogs.size, news.size, twitter.size),\n",
    "           num.lines = c(length(blogs), length(news), length(twitter)),\n",
    "           num.words = c(sum(blogs.words), sum(news.words), sum(twitter.words)),\n",
    "           mean.num.words = c(mean(blogs.words), mean(news.words), mean(twitter.words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cleaning and subsetting (2%) data for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.sample <- c(sample(blogs, length(blogs) * 0.0002),\n",
    "                 sample(news, length(news) * 0.0002),\n",
    "                 sample(twitter, length(twitter) * 0.0002))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "also installing the dependencies ‘NLP’, ‘slam’\n",
      "\n",
      "Updating HTML index of packages in '.Library'\n",
      "Making 'packages.html' ... done\n",
      "Loading required package: NLP\n"
     ]
    }
   ],
   "source": [
    "install.packages(\"tm\")\n",
    "library(tm)\n",
    "corpus <- VCorpus(VectorSource(data.sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus <- tm_map(corpus, tolower)\n",
    "corpus <- tm_map(corpus, removePunctuation)\n",
    "corpus <- tm_map(corpus, removeNumbers)\n",
    "corpus <- tm_map(corpus, stripWhitespace)\n",
    "corpus <- tm_map(corpus, PlainTextDocument)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tokenize sample into unigrams, bigrams and trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BigramTokenizer <-\n",
    "  function(x)\n",
    "    unlist(lapply(ngrams(words(x), 2), paste, collapse = \" \"), use.names = FALSE)\n",
    "TrigramTokenizer <-\n",
    "  function(x)\n",
    "    unlist(lapply(ngrams(words(x), 3), paste, collapse = \" \"), use.names = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Words frequency\n",
    "freq_words <- function(tdm){\n",
    "  freq <- sort(rowSums(as.matrix(tdm)), decreasing=TRUE)\n",
    "  freq_df <- data.frame(word=names(freq), freq=freq)\n",
    "  return(freq_df)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unigram <- removeSparseTerms(TermDocumentMatrix(corpus), 0.9999)\n",
    "unigram_freq <- freq_words(unigram)\n",
    "\n",
    "bigram <- removeSparseTerms(TermDocumentMatrix(corpus, control = list(tokenize = BigramTokenizer)), 0.9999)\n",
    "bigram_freq <- freq_words(bigram)\n",
    "\n",
    "trigram <- removeSparseTerms(TermDocumentMatrix(corpus, control = list(tokenize = TrigramTokenizer)), 0.9999)\n",
    "trigram_freq <- freq_words(trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "makePlot <- function(data, label) {\n",
    "  ggplot(data[1:20,], aes(reorder(word, -freq), freq)) +\n",
    "         labs(x = label, y = \"Frequency\") +\n",
    "         theme(axis.text.x = element_text(angle = 60, size = 12, hjust = 1)) +\n",
    "         geom_bar(stat = \"identity\", fill = I(\"orange\"))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
